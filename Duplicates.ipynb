{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with duplicates is really tricky because removing or not the duplicates will influene the model on putting more or less weights associated with the features\n",
    "\n",
    "For example, when training sets contain duplicates, the corresponding model puts more weight on getting these examples correct. **So** we have to make sure if the duplicates are real a represent well the domain or if the duplicates don't represent the domain. The duplicates indicate frequency which is important.\n",
    "\n",
    "**It basicaly comes down to the question whether the dataset you have resembles the real world or if it doesn't**\n",
    "\n",
    "So, if the duplicate don't represent the real world and are due to an error we should remove. On the other hand, if the duplicates represent a real world (e.g., an event that occurs more times in the real world) we should leave the duplicates in so the model can assign a higher weight to those examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note**\n",
    "- Duplicated elements inthe test data serve no real purpose. You've tested the model on that particular problem once, why would you do it agian, when you'd expect the exact same answer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two possible choices:\n",
    "- Remove \n",
    "- Don't remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10372, 44)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Smaller_Building_Permits.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases when duplicates don't represent the real world or domain\n",
    "Duplicate data does not add any value but make the algorithm slower\n",
    "Duplicates are an extreme case of nonrandom sampling, and they bias your fitted model. Including them will essentially lead to the model overfitting this subset of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\narguments:\\n    - subset - only considers a subset of columns for identifying duplicates\\n    - keep{‘first’, ‘last’, False}, default ‘first’ - False deletes all duplicates\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates() # pandas built in function\n",
    "'''\n",
    "arguments:\n",
    "    - subset - only considers a subset of columns for identifying duplicates\n",
    "    - keep{‘first’, ‘last’, False}, default ‘first’ - False deletes all duplicates\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't remove duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If domains where it is proven that duplicates happen in the real world, we should keep the duplicates to assure that the data represents well the distributions of the real world\n",
    "\n",
    "For example, if you remove your duplicates, a four-leaf clover is as significant as a regular, three-leaf clover, since each will occur once, whereas in real life there is a four-leaf clover for every 10,000 regular clovers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we don't have to do anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
