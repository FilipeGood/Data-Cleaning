{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Workflow**\n",
    "    1. Count missing values\n",
    "    2. Check why are they missing - missing values can be due to a lot of things\n",
    "        - It really depends on the origin of the data and the context it was generated. For example, for a survey, a Salary field with an empty value, or a number 0, or an invalid value (a string for example) can be considered \"missing data\".\n",
    "    3. Decide what to do with missing values based on the 2 step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Its important to look at the data and understand why the data is missing**:\n",
    "- Is this value missing because it wasn't recorded or because it doesn't exist?\n",
    "\n",
    "If the value is missing because **it doesn't exist** (like the height of the oldest child of someone who doesn't have any children) then it doesn't make sense to try and guess what it migth be.\n",
    "\n",
    "We can also **drop** if the missing values in a column rarely happend and occur at random, or if most of the column's values are missing\n",
    "\n",
    "\n",
    "\n",
    "*On the other hand*, if a value is missing because it wasn't recorded, then we can try to guess what it might have been based on the other values in that column and row => **Imputation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Strategies:\n",
    "- Delete missing rows \n",
    "- Delete features that contain more than X% of missing values\n",
    "- Replace with the next value\n",
    "- Replace with mean (for numerical)\n",
    "- Replace with mode (for categorical)\n",
    "- Replace with median (for numerical)\n",
    "- Impute with KNN Imputer\n",
    "- Impute with Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (22,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(198900, 43)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('Building_Permits.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Permit Number                                  0\n",
       "Permit Type                                    0\n",
       "Permit Type Definition                         0\n",
       "Permit Creation Date                           0\n",
       "Block                                          0\n",
       "Lot                                            0\n",
       "Street Number                                  0\n",
       "Street Number Suffix                      196684\n",
       "Street Name                                    0\n",
       "Street Suffix                               2768\n",
       "Unit                                      169421\n",
       "Unit Suffix                               196939\n",
       "Description                                  290\n",
       "Current Status                                 0\n",
       "Current Status Date                            0\n",
       "Filed Date                                     0\n",
       "Issued Date                                14940\n",
       "Completed Date                            101709\n",
       "First Construction Document Date           14946\n",
       "Structural Notification                   191978\n",
       "Number of Existing Stories                 42784\n",
       "Number of Proposed Stories                 42868\n",
       "Voluntary Soft-Story Retrofit             198865\n",
       "Fire Only Permit                          180073\n",
       "Permit Expiration Date                     51880\n",
       "Estimated Cost                             38066\n",
       "Revised Cost                                6066\n",
       "Existing Use                               41114\n",
       "Existing Units                             51538\n",
       "Proposed Use                               42439\n",
       "Proposed Units                             50911\n",
       "Plansets                                   37309\n",
       "TIDF Compliance                           198898\n",
       "Existing Construction Type                 43366\n",
       "Existing Construction Type Description     43366\n",
       "Proposed Construction Type                 43162\n",
       "Proposed Construction Type Description     43162\n",
       "Site Permit                               193541\n",
       "Supervisor District                         1717\n",
       "Neighborhoods - Analysis Boundaries         1725\n",
       "Zipcode                                     1716\n",
       "Location                                    1700\n",
       "Record ID                                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_count = df.isnull().sum()\n",
    "missing_values_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198900, 43)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.26002315058403 %\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Percentage of cells that contain missing values!\n",
    "'''\n",
    "# how many total missing values do we have?\n",
    "total_cells = np.product(df.shape)\n",
    "total_missing = missing_values_count.sum()\n",
    "\n",
    "# percent of data that is missing\n",
    "percent_missing = (total_missing/total_cells) * 100\n",
    "print(percent_missing ,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete missing rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By removing a whole observation just because that observation contains a missing value in one cell, we can loose relevant information that is in the other features/cells\n",
    "\n",
    "*This technique is good when a feature has few missing values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 43)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing_rows_deleted = df.dropna()\n",
    "df_missing_rows_deleted.shape\n",
    "\n",
    "# In this case it deletes all the rows because all contain at least one missing value!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Delete features that contain more than X% of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique is good for features that have a high percentage of missing values.\n",
    "If a certain features has a high percentage of missing values, it's not a good idea to try and gess the values because we don't have enough data to infer.\n",
    "\n",
    "**First we have to check if the missing values in a features have a certain meaning**\n",
    "\n",
    "After we still have to decide what to do with the other features that contain missing values but the percentage is lower than X%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Permit Number                              0.000000\n",
       "Permit Type                                0.000000\n",
       "Permit Type Definition                     0.000000\n",
       "Permit Creation Date                       0.000000\n",
       "Block                                      0.000000\n",
       "Lot                                        0.000000\n",
       "Street Number                              0.000000\n",
       "Street Number Suffix                      98.885872\n",
       "Street Name                                0.000000\n",
       "Street Suffix                              1.391654\n",
       "Unit                                      85.178984\n",
       "Unit Suffix                               99.014077\n",
       "Description                                0.145802\n",
       "Current Status                             0.000000\n",
       "Current Status Date                        0.000000\n",
       "Filed Date                                 0.000000\n",
       "Issued Date                                7.511312\n",
       "Completed Date                            51.135747\n",
       "First Construction Document Date           7.514329\n",
       "Structural Notification                   96.519859\n",
       "Number of Existing Stories                21.510307\n",
       "Number of Proposed Stories                21.552539\n",
       "Voluntary Soft-Story Retrofit             99.982403\n",
       "Fire Only Permit                          90.534439\n",
       "Permit Expiration Date                    26.083459\n",
       "Estimated Cost                            19.138260\n",
       "Revised Cost                               3.049774\n",
       "Existing Use                              20.670689\n",
       "Existing Units                            25.911513\n",
       "Proposed Use                              21.336853\n",
       "Proposed Units                            25.596280\n",
       "Plansets                                  18.757667\n",
       "TIDF Compliance                           99.998994\n",
       "Existing Construction Type                21.802916\n",
       "Existing Construction Type Description    21.802916\n",
       "Proposed Construction Type                21.700352\n",
       "Proposed Construction Type Description    21.700352\n",
       "Site Permit                               97.305681\n",
       "Supervisor District                        0.863248\n",
       "Neighborhoods - Analysis Boundaries        0.867270\n",
       "Zipcode                                    0.862745\n",
       "Location                                   0.854701\n",
       "Record ID                                  0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rows = df.shape[0]\n",
    "missing_feature_percentage = missing_values_count /total_rows*100\n",
    "missing_feature_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features that have more than 30%\n",
    "to_drop = missing_feature_percentage[missing_feature_percentage > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198900, 34)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing_features_drop  =df.drop(to_drop.index.tolist(), 1)\n",
    "df_missing_features_drop.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace with next value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique is great for time series data where the data is collected in short intervals of time. In these cases, the next value can be very similar to the missing value because the data has been collect almost at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bfill uses the next valid observation to fill gap.\n",
    "# ffill uses the last valid observation\n",
    "df_next_value = df.fillna(method='bfill')\n",
    "df_next_value = df_next_value.fillna(method='ffill') # for the last row.\n",
    "\n",
    "df_next_value.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace with mean (for numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique has the advantage that is fast, but it only takes into account a single attribute thus not counting with the possible relations with other features (**Univariate Imputing)**. It also does not add new relevant information to the feature and can reduce the variability of the data\n",
    "\n",
    "**Mean is most useful when the original data is not skewed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_mean = df.fillna(df.mean())\n",
    "df_with_mean.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace with mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pros and cons of this technique are similar to the ones of replacing with mean\n",
    "\n",
    "It works well with categorical features but can introduce bias in the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_mode = df.fillna(df.mean())\n",
    "df_with_mode.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace with median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pros and cons of this technique are similar to the ones of replacing with mean\n",
    "\n",
    "But imputing with the median makes more sense than with the mean when the data is skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_median = df.fillna(df.median())\n",
    "df_with_median.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputers that take into account the other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two techiques are **very good** because they use the entire dataset to estimate the missing values. This is good because they don't work on an attribute level. They use the relationships between the different features in order to estimate the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impute with KNN Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Provides imputation for filling in missing values unsing the k-nearest neighbors approach\n",
    "- By default, a euclidean distance metric that supports missing values is used to find the nearest neighbors\n",
    "- Each missing feature is imputed using values from n_neighbors nearest neighbors that have a value for the feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute.KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors = 10)\n",
    "imputed_df = df.fit_transform(df.values)\n",
    "imputed_df.isnull().any().any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impute with Iterative Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Models each feature with missing values as a function of other features, and uses that estimate for imputation\n",
    "- At each step, a feature column is designated as output **y**, and the other feature columns are treated as inputs **X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imp = IterativeImputer(random_state=42) # can specify the estimator - default is BayesianRidge\n",
    "\n",
    "imputed_df = df.fit_transform(df.values)\n",
    "imputed_df.isnull().any().any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THERE ISN'T A PERFECT SOLUTION** \n",
    "\n",
    "*It really depends on the dataset and why is the value missing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
